{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gBxcjRDEliK"
   },
   "source": [
    "# Graph Neural Networks\n",
    "\n",
    "In this tutorial, we will explore the implementation of graph neural networks and investigate what representations these networks learn. Along the way, we'll see how PyTorch Geometric and TensorBoardX can help us with constructing and training graph models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BwdncyH6CEZ9"
   },
   "source": [
    "# Preliminaries: PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feCFN2K3Hcte"
   },
   "source": [
    "We'll first demonstrate some essential features of PyTorch which we'll use throughout. PyTorch is a general machine learning library that allows us to dynamically define computation graphs which we'll use to describe our models and their training processes.\n",
    "\n",
    "We'll start by importing everything we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YNtPXYKmCVow"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn.metrics as metrics\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7L1yNOAILmW"
   },
   "source": [
    "We'll first download and load in a dataset (here the MNIST handwritten digits dataset) through the `DataLoader` utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3M3Ckk-xEvXm"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "## transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "## download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "## download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8V5S0a4gaR3",
    "outputId": "a6111398-9f7f-4f92-bc9c-67a42b8f6e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1647, 0.4627, 0.8588, 0.6510, 0.4627,\n",
      "          0.4627, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.4039, 0.9490, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "          0.9961, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0706, 0.9098, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "          0.9961, 0.9333, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4078, 0.9569, 0.9961, 0.8784, 0.9961,\n",
      "          0.9961, 0.9961, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9961, 0.8235, 0.9961,\n",
      "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.8078, 0.9961, 0.9961,\n",
      "          0.9961, 0.9961, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8196, 0.9961,\n",
      "          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.5373, 0.9922, 0.9961,\n",
      "          0.9961, 0.9961, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1569, 0.8392, 0.9804, 0.9961, 0.9961, 0.9961,\n",
      "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.3176, 0.9686, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "          0.9961, 0.9961, 0.5725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.4314, 0.9647, 0.9961, 0.9961, 0.9961,\n",
      "          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.3490, 0.3490, 0.3647,\n",
      "          0.9412, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
      "          0.5020, 0.9961, 0.8588, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
      "          0.9961, 0.9961, 0.8392, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5412,\n",
      "          0.9961, 0.9961, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.6941,\n",
      "          0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.9412,\n",
      "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961,\n",
      "          0.8431, 0.2471, 0.1412, 0.0000, 0.2000, 0.3490, 0.8078, 0.9961,\n",
      "          0.9961, 0.5451, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.7725,\n",
      "          0.9961, 0.9961, 0.8706, 0.7059, 0.9451, 0.9961, 0.9961, 0.9922,\n",
      "          0.8353, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490,\n",
      "          0.4118, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9255,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0275, 0.4588, 0.4588, 0.6471, 0.9961, 0.9961, 0.9373, 0.1961,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]), 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "print(trainset[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1jlPrOmIlIJ"
   },
   "source": [
    "Our goal here will be to train a model to classify digits based on their pictures. Let's define the model we'll use for this task, which will consist of a convolutional layer followed by two fully-connected layers. Our model is a subclass of `nn.Module`; modules must implement a `forward()` function which defines exactly what operations get applied to the inputted data.\n",
    "\n",
    "Note that `MyModel` makes uses of the predefined modules `Conv2d` and `Linear`, which it instantiates in its constructor. Running data `x` through a module `conv1` simply consists of calling it like a function: `out = conv1(x)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y8zge1JmEyAD"
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # 28x28x1 => 26x26x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # flatten => 32 x (32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        #x = x.view(32, -1)\n",
    "\n",
    "        # 32 x (32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81sghL-oijxb",
    "outputId": "ad7d3585-e4b6-4e4b-fca0-4a625fb01b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0', dtype=torch.float64)\n",
      "tensor([[3., 3.],\n",
      "        [7., 7.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.ones((2,2))\n",
    "\n",
    "ta = torch.tensor(a, dtype=float).to('cuda:0')\n",
    "tb = torch.ones(2,2, dtype=float).to('cuda:0')\n",
    "\n",
    "print(ta)\n",
    "print(ta @ tb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wbgpv4yU0MF"
   },
   "source": [
    "We train our model, printing out its training accuracy along the way. We start by instantiating a model instance `model`, a loss function module `criterion` and optimizer `optimizer`, which will adjust the parameters of our model in order to minimize the loss output by `criterion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JhN99DECU6Hr"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6jDPUQiWEu4"
   },
   "source": [
    "Now let's write our training loop. For each minibatch (accessed by enumerating through our data loader `trainloader`), we run our data through `model` in a forward pass, then compute the loss with `criterion`. We call `optimizer.zero_grad()` to zero out the gradients from the previous round of training, followed by `loss.backward()` to backpropagate the new round of gradients and finally `optimizer.step()` to adjust the model parameters based on these gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGoOz_zjE2EH",
    "outputId": "3c36a7f8-f673-49f2-9120-727f3458c93b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.5906 | Train Accuracy: 0.88\n",
      "Epoch: 1 | Loss: 1.4928 | Train Accuracy: 0.97\n",
      "Epoch: 2 | Loss: 1.4820 | Train Accuracy: 0.98\n",
      "Epoch: 3 | Loss: 1.4783 | Train Accuracy: 0.99\n",
      "Epoch: 4 | Loss: 1.4751 | Train Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    ## training step\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ## forward + backprop + loss\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ## update model params\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += (torch.argmax(logits, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "\n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvK4hr1OXLWu"
   },
   "source": [
    "Lastly, we can run just the forward pass of our model in order to run it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umfoz-KMW7Rs",
    "outputId": "fce5b46d-107e-4795-e4e0-d523e7b0cfc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += (torch.argmax(outputs, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    preds = torch.argmax(outputs, 1).flatten().cpu().numpy()\n",
    "\n",
    "print('Test Accuracy: %.2f'%(test_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ4OIG8r5EfI"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyzIhe0O5ije"
   },
   "source": [
    "Let's first install PyTorch Geometric (which we'll use for creating graph neural networks) and TensorboardX (which we'll use to visualize training progress):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "X9mEE50x-Wir"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LwTG61Ibo4dG",
    "outputId": "55e140f7-c49d-486d-ad26-c9fc7c03bb92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Running command python setup.py egg_info\n",
      "  running egg_info\n",
      "  creating /tmp/pip-pip-egg-info-ofgaprza/torch_scatter.egg-info\n",
      "  writing /tmp/pip-pip-egg-info-ofgaprza/torch_scatter.egg-info/PKG-INFO\n",
      "  writing dependency_links to /tmp/pip-pip-egg-info-ofgaprza/torch_scatter.egg-info/dependency_links.txt\n",
      "  writing requirements to /tmp/pip-pip-egg-info-ofgaprza/torch_scatter.egg-info/requires.txt\n",
      "  writing top-level names to /tmp/pip-pip-egg-info-ofgaprza/torch_scatter.egg-info/top_level.txt\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-ofgaprza/torch_scatter.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/tmp/pip-pip-egg-info-ofgaprza/torch_scatter.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory 'test'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-ofgaprza/torch_scatter.egg-info/SOURCES.txt'\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: torch-scatter\n",
      "  Running command python setup.py bdist_wheel\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-cpython-310\n",
      "  creating build/lib.linux-x86_64-cpython-310/torch_scatter\n",
      "  copying torch_scatter/segment_coo.py -> build/lib.linux-x86_64-cpython-310/torch_scatter\n",
      "  copying torch_scatter/__init__.py -> build/lib.linux-x86_64-cpython-310/torch_scatter\n",
      "  copying torch_scatter/segment_csr.py -> build/lib.linux-x86_64-cpython-310/torch_scatter\n",
      "  copying torch_scatter/scatter.py -> build/lib.linux-x86_64-cpython-310/torch_scatter\n",
      "  copying torch_scatter/utils.py -> build/lib.linux-x86_64-cpython-310/torch_scatter\n",
      "  copying torch_scatter/placeholder.py -> build/lib.linux-x86_64-cpython-310/torch_scatter\n",
      "  copying torch_scatter/testing.py -> build/lib.linux-x86_64-cpython-310/torch_scatter\n",
      "  creating build/lib.linux-x86_64-cpython-310/torch_scatter/composite\n",
      "  copying torch_scatter/composite/softmax.py -> build/lib.linux-x86_64-cpython-310/torch_scatter/composite\n",
      "  copying torch_scatter/composite/logsumexp.py -> build/lib.linux-x86_64-cpython-310/torch_scatter/composite\n",
      "  copying torch_scatter/composite/std.py -> build/lib.linux-x86_64-cpython-310/torch_scatter/composite\n",
      "  copying torch_scatter/composite/__init__.py -> build/lib.linux-x86_64-cpython-310/torch_scatter/composite\n",
      "  running egg_info\n",
      "  writing torch_scatter.egg-info/PKG-INFO\n",
      "  writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
      "  writing requirements to torch_scatter.egg-info/requires.txt\n",
      "  writing top-level names to torch_scatter.egg-info/top_level.txt\n",
      "  reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory 'test'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  running build_ext\n",
      "  /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
      "    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "  building 'torch_scatter._version_cpu' extension\n",
      "  creating build/temp.linux-x86_64-cpython-310\n",
      "  creating build/temp.linux-x86_64-cpython-310/csrc\n",
      "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_PYTHON -Icsrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c csrc/version.cpp -o build/temp.linux-x86_64-cpython-310/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_version_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/version.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/torch_scatter/_version_cpu.so -s\n",
      "  building 'torch_scatter._version_cuda' extension\n",
      "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/version.cpp -o build/temp.linux-x86_64-cpython-310/csrc/version.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_version_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n"
     ]
    }
   ],
   "source": [
    "!pip install --verbose --no-cache-dir torch-scatter\n",
    "!pip install --verbose --no-cache-dir torch-sparse\n",
    "!pip install --verbose --no-cache-dir torch-cluster\n",
    "!pip install torch-geometric\n",
    "!pip install tensorboardX\n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z550TutV5vhQ"
   },
   "source": [
    "Import everything we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlFlxfL5dgn2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCgqxSiq6I4B"
   },
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Nc20DEc6PO5"
   },
   "source": [
    "The `GNNStack` is our general framework for a GNN which can handle different types of convolutional layers, and both node and graph classification. The `build_conv_model` method determines which type of convolutional layer to use for the given task -- here we choose to use a graph convolutional network for node classification, and a graph isomorphism network for graph classification. Note that PyTorch Geometric provides out-of-the-box modules for these layers, which we use here. The model consists of 3 layers of convolution, followed by mean pooling in the case of graph classification, followed by two fully-connected layers. Since our goal here is classification, we use a negative log-likelihood loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymy1pgN5oNQG"
   },
   "outputs": [],
   "source": [
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.task = task\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        for l in range(2):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        if not (self.task == 'node' or self.task == 'graph'):\n",
    "            raise RuntimeError('Unknown task.')\n",
    "\n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 3\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        if self.task == 'node':\n",
    "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        else:\n",
    "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "          x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1:\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        if self.task == 'graph':\n",
    "            x = pyg_nn.global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        return emb, F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l8hy4NSvu7J"
   },
   "source": [
    "Here pyg_nn.GCNConv and pyg_nn.GINConv are instances of MessagePassing. They define a single layer of graph convolution, which can be decomposed into:\n",
    "* Message computation\n",
    "* Aggregation\n",
    "* Update\n",
    "* Pooling\n",
    "\n",
    "Here we give an example of how to subclass the pytorch geometric MessagePassing class to derive a new model (rather than using existing GCNConv and GINConv).\n",
    "\n",
    "We make use of `MessagePassing`'s key building blocks:\n",
    "- `aggr='add'`: The aggregation method to use (\"add\", \"mean\" or \"max\").\n",
    "- `propagate()`: The initial call to start propagating messages. Takes in the edge indices and any other data to pass along (e.g. to update node embeddings).\n",
    "- `message()`: Constructs messages to node i. Takes any argument which was initially passed to propagate().\n",
    "- `update()`: Updates node embeddings. Takes in the output of aggregation as first argument and any argument which was initially passed to propagate().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_0yhAPgvttr"
   },
   "outputs": [],
   "source": [
    "class CustomConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.lin_self = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n",
    "\n",
    "        # Transform node feature matrix.\n",
    "        self_x = self.lin_self(x)\n",
    "        #x = self.lin(x)\n",
    "\n",
    "        return self_x + self.propagate(edge_index, size=(x.size(0), x.size(0)), x=self.lin(x))\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index, size):\n",
    "        # Compute messages\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bANNrQoh8xjF"
   },
   "source": [
    "# Training setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBwQxvFY83TG"
   },
   "source": [
    "We train the model in a standard way here, running it forwards to compute its predicted label distribution and backpropagating the error. Note the task setup in our graph setting: for node classification, we define a subset of nodes to be training nodes and the rest of the nodes to be test nodes, and mask out the test nodes during training via `batch.train_mask`. For graph classification, we use 80% of the graphs for training and the remainder for testing, as in other classification settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5nqB3HHoHc7"
   },
   "outputs": [],
   "source": [
    "def train(dataset, task, writer):\n",
    "    if task == 'graph':\n",
    "        data_size = len(dataset)\n",
    "        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=64, shuffle=True)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=64, shuffle=True)\n",
    "    else:\n",
    "        test_loader = loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task=task)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(200):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            embedding, pred = model(batch)\n",
    "            label = batch.y\n",
    "            if task == 'node':\n",
    "                pred = pred[batch.train_mask]\n",
    "                label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, test_acc))\n",
    "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC8IPZSOXraQ"
   },
   "source": [
    "Test time, for the CiteSeer/Cora node classification task, there is only 1 graph. So we use masking to determine validation and test set.\n",
    "\n",
    "For graph classification tasks, a subset of graphs is considered validation / test graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvUBHtZaXo2h"
   },
   "outputs": [],
   "source": [
    "def test(loader, model, is_validation=False):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "\n",
    "        if model.task == 'node':\n",
    "            mask = data.val_mask if is_validation else data.test_mask\n",
    "            # node classification: only evaluate on nodes in test set\n",
    "            pred = pred[mask]\n",
    "            label = data.y[mask]\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "    if model.task == 'graph':\n",
    "        total = len(loader.dataset)\n",
    "    else:\n",
    "        total = 0\n",
    "        for data in loader.dataset:\n",
    "            total += torch.sum(data.test_mask).item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUo2Ve8c9wGp"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frumUA-l9zua"
   },
   "source": [
    "Let's train our model and visualize its progress. First, run this snippet to generate a link to TensorBoardX, which will take you to a page where you can visualize the loss and accuracy curves of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IS1dPinuyPCy"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(\"./log\")\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUfdqmUI-HtW"
   },
   "source": [
    "Now run this snippet to start the training. When it's finished, you should be able to see its training and test performance over time on the TensorBoardX page. If you run the snippet multiple times, you will be able to see multiple training curves and compare them.\n",
    "\n",
    "We start with a graph classification task on the IMDB-BINARY dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf4-g8wT-qsj"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "task = 'graph'\n",
    "\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMeWZW8-_Eg8"
   },
   "source": [
    "Here we try a node classification task on the Citeseer citation network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pREw2UQuBH4"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = Planetoid(root='/tmp/cora', name='cora')\n",
    "task = 'node'\n",
    "\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5xf-UrHD7rp"
   },
   "source": [
    "# Visualizing node embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cESIeZB_Nqf"
   },
   "source": [
    "One great quality about graph neural networks is that, like other deep methods, their hidden layers provide low-dimensional representations of our data. In the case of node classification, we get a low-dimensional representation for each node in our graph. Let's visualize the output of the last convolutional layer in our node classification GNN via TSNE, a method for plotting high-dimensional data. Nodes are colored according to their labels. We see that nodes with similar labels tend to be near each other in the embedding space, a good indication that our model has learned a useful representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i31kOOTKuLd7"
   },
   "outputs": [],
   "source": [
    "color_list = [\"red\", \"orange\", \"green\", \"blue\", \"purple\", \"brown\"]\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "embs = []\n",
    "colors = []\n",
    "for batch in loader:\n",
    "    emb, pred = model(batch)\n",
    "    embs.append(emb)\n",
    "    colors += [color_list[y] for y in batch.y]\n",
    "embs = torch.cat(embs, dim=0)\n",
    "\n",
    "xs, ys = zip(*TSNE().fit_transform(embs.detach().numpy()))\n",
    "plt.scatter(xs, ys, color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uU6STM21EJT3"
   },
   "source": [
    "# Learning unsupervised embeddings with graph autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLvR2pQSAk4H"
   },
   "source": [
    "Finally, GNNs fit nicely in the framework of other neural approaches, and can be used as part of autoencoder techniques, pretraining and multitask learning methods, etc. Here we explore the idea of neural network representations further by building a graph autoencoder which learns these representations in a completely unsupervised way. In contrast to the previous example, we do not make use of the given node labels when training this representation. Instead, we encode the nodes in our network in a low-dimensional space in such a way that the embeddings can be decoded into a reconstruction of the original network. We use graph convolutional layers in the encoder.\n",
    "\n",
    "You can again use TensorBoardX here to visualize the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phCgm5idq6TH"
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = pyg_nn.GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    writer.add_scalar(\"loss\", loss.item(), epoch)\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)\n",
    "\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = Planetoid(\"/tmp/citeseer\", \"Citeseer\", T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "channels = 16\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA availability:', torch.cuda.is_available())\n",
    "\n",
    "# encoder: written by us; decoder: default (inner product)\n",
    "model = pyg_nn.GAE(Encoder(dataset.num_features, channels)).to(dev)\n",
    "labels = data.y\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = model.split_edges(data)\n",
    "x, train_pos_edge_index = data.x.to(dev), data.train_pos_edge_index.to(dev)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train(epoch)\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    writer.add_scalar(\"AUC\", auc, epoch)\n",
    "    writer.add_scalar(\"AP\", ap, epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcSCNm-GDTtQ"
   },
   "source": [
    "Finally, we plot our embeddings (the output of the encoder) with TSNE. We color each node embedding according to its label -- but note that we did not use any label information when training our encoder. Nodes with the same label are nevetheless close together in the embedding space. The model has learned the community structure without supervision!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-R_EAYAz5kk"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z = model.encode(x, train_pos_edge_index)\n",
    "colors = [color_list[y] for y in labels]\n",
    "\n",
    "xs, ys = zip(*TSNE().fit_transform(z.cpu().detach().numpy()))\n",
    "plt.scatter(xs, ys, color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd_BEZnSyyWw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THEORY QUESTIONS\n",
    "\n",
    "\n",
    "#### Question 1\n",
    "\n",
    "On initial impression, one might implement a deep neural network for graphs by simply using an adjacency matrix as input, by flattening said matrix and feeding it to a multilayer perceptron like so…\n",
    "\n",
    "$$\n",
    "z_G=MLP(A[1]⊕A[2]⊕…⊕A[[V]])\n",
    "$$\n",
    "\n",
    "Where $A[i]∈R^{|V|}$  denotes a row of the adjacency matrix and the $⊕$ symbol denotes vector concatenation. Why is this not a viable solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Because the order of the nodes in the adjacency matrix is arbitrary, using this method would not be permutation invariant, and thus not appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "In this problem let $(S,x)$ denote a graph signal, where the graph signal $x$ is supported on a shift operator $S$ which itself is a matrix.  Let’s say that a GNN of $L$ layers recursively process the output of previous layers. The GNN output can be parameterized by the tensor $H$. This GNN can be generalized like so...\n",
    "\n",
    "$$\n",
    "x_l=\\sigma\\left[\\sum_{k=0}^{K-1}{h_{lk}S^kx_{l-1}}\\right]=\\sigma\\left[H_l\\left(S\\right)x_{l-1}\\right]\\ \\ \\ \\ \\ \\phi\\left(x;S,H\\right)=x_L\n",
    "$$\n",
    "\n",
    "Letting the shift operator be $S$ with input signal $x$, and their permutations be $\\hat{S}=P^TSP$ and $\\hat{x}=P^Tx$ respectively, where $P$ represents the permutation matrix, such that the network is permutation equivariant if $\\phi\\left(\\hat{x};\\hat{S},H\\right)=P^T\\phi\\left(x;S,H\\right)$. Prove the permutation equivariance of the GNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "$$\n",
    "x_l=\\sigma\\left[\\sum_{k=0}^{K-1}{h_{lk}S^kx_{l-1}}\\right]=\\sigma\\left[H_l\\left(S\\right)x_{l-1}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\hat{x}}_l=\\sigma\\left[\\sum_{k=0}^{K-1}{h_{lk}{\\hat{S}}^k{\\hat{x}}_{l-1}}\\right]=\\sigma\\left[H_l\\left(\\hat{S}\\right){\\hat{x}}_{l-1}\\right]\n",
    "$$\n",
    "\n",
    "Then Prove by Induction. First assume permutation equivariance of a single layer, ${\\hat{x}}_{l-1}=P^Tx_{l-1}$\n",
    "\n",
    "$$\n",
    "{\\hat{x}}_l=\\sigma\\left[P^TH_l\\left(\\hat{S}\\right)x_{l-1}\\right]=P^T\\sigma\\left[H_l\\left(\\hat{S}\\right)x_{l-1}\\right]=P^Tx_l\n",
    "$$\n",
    "\n",
    "Therefore if ${\\hat{x}}_{l-1}=P^Tx_{l-1}$ then ${\\hat{x}}_l=P^Tx_l$ and the induction is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.1\n",
    "\n",
    "The simplest versions of neighborhood aggregation that can occur in message passing, involves taking the sum of each neighbor embedding like so…\n",
    "\n",
    "$$\n",
    "m_{N\\left(u\\right)}=\\sum_{v\\in N(u)} h_v\n",
    "$$\n",
    "\n",
    "In a graph which has wildly varying node degrees, what negative effects might using this form of aggregation have on the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "In graphs with extremely wildly varying node degrees, using this form of simple message passing can lead to instability and sensitivity in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.2\n",
    "\n",
    "One solution to solve this problem would be to normalize the aggregation with respect to the degrees of the nodes, the simplest version of this involves taking the average instead of the sum like so…\n",
    "\n",
    "$$\n",
    "m_{N\\left(u\\right)}=\\frac{1}{|N\\left(u\\right)|}\\sum_{v\\in N(u)} h_v\n",
    "$$\n",
    "\n",
    "That being said, what other problems could this lead to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "One problem with this normalization solution, is that normalizing during aggregation can lead to information loss. For instance, it may become harder to distinguish between nodes of varying degrees, using learned embeddings. For this reason, normalization is not always appropriate, and in simple GNNs, it can work to the detriment of the model, as opposed to a simple summation aggregation. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
